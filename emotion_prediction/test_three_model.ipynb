{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d89bf05",
   "metadata": {},
   "source": [
    "## Testing a single head model on custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b908fb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from ignite.metrics import Accuracy, Loss, Fbeta, recall, precision\n",
    "from transformers import AdamW, AutoModelForSequenceClassification, AutoTokenizer\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from utils import load_dataset, tokenize_dataset, create_dataloader\n",
    "import os\n",
    "import glob\n",
    "from models import ThreeHeadedMonster\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "ARTEMIS_EMOTIONS = ['amusement', 'awe', 'contentment', 'excitement',\n",
    "                'anger', 'disgust',  'fear', 'sadness', 'something else']\n",
    "EMOTION_ID = {e: i for i, e in enumerate(ARTEMIS_EMOTIONS)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8cbb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_version = 'xlm-roberta-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(bert_version, padding_side='right')\n",
    "\n",
    "data_root_path = 'dataset/'\n",
    "model_root_path = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb88d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = glob.glob('three_model/*')\n",
    "print(all_models)\n",
    "langs = ['english', 'arabic', 'chinese']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedd67e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang in langs:\n",
    "    for model_path in all_models:\n",
    "        # loading the model\n",
    "        model_path = os.path.join(model_root_path, model_path)\n",
    "        model_name = model_path.split('/')[-1]\n",
    "        model = ThreeHeadedMonster.load_pretrained(model_path, num_emo_classes=9)\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "\n",
    "        data_path = os.path.join(data_root_path, f'test_{lang}/test_{lang}.csv')\n",
    "        sentences, labels = load_dataset(data_path, ARTEMIS_EMOTIONS, split='test')\n",
    "        tokens, masks = tokenize_dataset(tokenizer, sentences)\n",
    "        dataloader = create_dataloader(tokens, masks, labels, batch_size=128, mode='test')\n",
    "        \n",
    "        # evaluation loop\n",
    "        print(f'========= {model_name} :: {lang} =========')\n",
    "        t = trange(len(dataloader), desc='ML')\n",
    "        model.eval()\n",
    "        metrics = {'Accuracy': Accuracy(), \n",
    "                   'Precision': precision.Precision(average=True), \n",
    "                   'Recall': recall.Recall(average=True), \n",
    "                   'F1': Fbeta(1),\n",
    "                   'Loss': Loss(F.cross_entropy)\n",
    "                  }\n",
    "        for metric in metrics.values():\n",
    "            metric.reset()\n",
    "        for step, batch in zip(t, dataloader):\n",
    "            input_ids = batch[0].to(device)\n",
    "            input_mask = batch[1].to(device)\n",
    "            labels = batch[2].to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids, \n",
    "                                token_type_ids=None, \n",
    "                                attention_mask=input_mask,\n",
    "                                language=lang) \n",
    "            for metric in metrics.values():\n",
    "                metric.update((outputs, labels.argmax(dim=1))) \n",
    "#             t.set_description(f'ML (loss={loss_avg.compute():.5f})')\n",
    "            t.set_description('ML')\n",
    "        for n, metric in metrics.items():\n",
    "            print(f'   {n}: {metric.compute():.5f}')\n",
    "        print(f'==========================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381e92bc",
   "metadata": {},
   "source": [
    "## 3-headed monster Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717d538e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading best model\n",
    "model_path = \"PATH TO BEST MODEL\"\n",
    "model = ThreeHeadedMonster.load_pretrained(model_path, num_emo_classes=9)\n",
    "model.to(device)\n",
    "model.eval();\n",
    "\n",
    "bert_version = 'xlm-roberta-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(bert_version, padding_side='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e175be",
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_classes = 9\n",
    "def load_dataset(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.dropna()\n",
    "    sentences = df['utterance']\n",
    "    labels = df['emotion'].apply(lambda x: x.lower()).replace('other', 'something else').values\n",
    "    labels_pt = torch.zeros((labels.shape[0], emo_classes))\n",
    "    for i, emo in enumerate(labels):\n",
    "        labels_pt[i, EMOTION_ID[emo]] = 1\n",
    "    tokenized = tokenizer(sentences.to_list(), add_special_tokens=True, max_length=128,\n",
    "                        truncation=True, padding='max_length', return_tensors='pt', return_attention_mask=True)\n",
    "    train_inputs, train_masks, train_labels = tokenized['input_ids'], tokenized['attention_mask'], labels_pt\n",
    "    batch_size = 2048\n",
    "    train_dataset = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "    train_sampler = SequentialSampler(train_dataset)\n",
    "    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\n",
    "    return df, train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c888127",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_df, en_train_dataloader = load_dataset(os.path.join(data_root_path, f'english/train/artemis_preprocessed.csv'))\n",
    "ar_df, ar_train_dataloader = load_dataset(os.path.join(data_root_path, f'arabic/train/artemis_preprocessed.csv'))\n",
    "ch_df, ch_train_dataloader = load_dataset(os.path.join(data_root_path, f'chinese/train/artemis_preprocessed.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2c046d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_df, sp_train_dataloader = load_dataset(os.path.join(data_root_path, f'test_spanish/test_spanish.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42029aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['english', 'arabic', 'chinese', 'spanish']\n",
    "dataloaders = {}\n",
    "for d in datasets:\n",
    "    dataloaders[d] = load_dataset(os.path.join(data_root_path, f'test_{d}/test_{d}.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d3d5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_dataloader, num_classes=3):\n",
    "    batch_size = train_dataloader.batch_size\n",
    "    all_scores = np.zeros((len(train_dataloader.dataset), num_classes))\n",
    "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model.predict_all(input_ids=b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "        all_scores[step*batch_size : (step+1)*batch_size] = outputs\n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fb313d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d068fde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mode(arr):\n",
    "    preds = np.zeros(arr.shape[0])\n",
    "    for i, row in enumerate(arr):\n",
    "        v, c = np.unique(row, return_counts=True)\n",
    "        idx = np.argmax(c) if np.any(c > 1) else np.random.choice(3)\n",
    "        preds[i] = v[idx]\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adcdcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d_name, (dff, dl) in dataloaders.items():\n",
    "    sp_emotions = evaluate_model(model, dl)\n",
    "    modes = get_mode(sp_emotions)\n",
    "    print(f'========== {d_name} ==========')\n",
    "    print(f' english score: {accuracy_score(dff[\"emotion_label\"].values, sp_emotions[:,0])}')\n",
    "    print(f' arabic score: {accuracy_score(dff[\"emotion_label\"].values, sp_emotions[:,1])}')\n",
    "    print(f' chinese score: {accuracy_score(dff[\"emotion_label\"].values, sp_emotions[:,2])}')\n",
    "    print(f' mode score: {accuracy_score(dff[\"emotion_label\"].values, modes)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97803c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mode(arr):\n",
    "    preds = np.zeros(arr.shape[0])\n",
    "    for i, row in enumerate(arr):\n",
    "        v, c = np.unique(row, return_counts=True)\n",
    "        idx = np.argmax(c) if np.any(c > 1) else np.random.choice(3)\n",
    "        preds[i] = v[idx]\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f626cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f' english score: {accuracy_score(sp_df[\"emotion_label\"].values, sp_emotions[:,0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea27f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f' arabic score: {accuracy_score(sp_df[\"emotion_label\"].values, sp_emotions[:,1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a75dc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f' chinese score: {accuracy_score(sp_df[\"emotion_label\"].values, sp_emotions[:,2])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2281bac",
   "metadata": {},
   "source": [
    "## Heat Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948e03e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_emotions = evaluate_model(model, en_train_dataloader)\n",
    "ar_emotions = evaluate_model(model, ar_train_dataloader)\n",
    "ch_emotions = evaluate_model(model, ch_train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9230e5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_df[['en_emo', 'ar_emo', 'ch_emo']] = en_emotions\n",
    "ar_df[['en_emo', 'ar_emo', 'ch_emo']] = ar_emotions\n",
    "ch_df[['en_emo', 'ar_emo', 'ch_emo']] = ch_emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85da24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_df.to_csv('monster_datasets/monster_english.csv', index=False)\n",
    "ar_df.to_csv('monster_datasets/monster_arabic.csv', index=False)\n",
    "ch_df.to_csv('monster_datasets/monster_chinese.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a69f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "ARTEMIS_EMOTIONS = ['amusement', 'awe', 'contentment', 'excitement',\n",
    "                'anger', 'disgust',  'fear', 'sadness', 'something else']\n",
    "EMOTION_ID = {e: i for i, e in enumerate(ARTEMIS_EMOTIONS)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b7da17",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_df = pd.read_csv('monster_datasets/monster_english.csv')\n",
    "ar_df = pd.read_csv('monster_datasets/monster_arabic.csv')\n",
    "ch_df = pd.read_csv('monster_datasets/monster_chinese.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616257ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_report(df, l1, l2):\n",
    "    y_true, y_pred = df[l1+'_emo'], df[l2+'_emo']\n",
    "    cm= confusion_matrix(y_true, y_pred, normalize='pred').round(3)\n",
    "    df_cm = pd.DataFrame(cm, index = [l1+'_'+i for i in ARTEMIS_EMOTIONS],\n",
    "                         columns = [l2+'_'+i for i in ARTEMIS_EMOTIONS])\n",
    "    plt.figure(figsize=(12,9))\n",
    "    sns.heatmap(df_cm, annot=True)\n",
    "    plt.show()\n",
    "    print(classification_report(y_true, y_pred, target_names=ARTEMIS_EMOTIONS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5800293d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat([en_df,ar_df,ch_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c9e0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_df = en_df\n",
    "l1 = 'en'\n",
    "l2 = 'ar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7566f481",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = lang_df[l1+'_emo'], lang_df[l2+'_emo']\n",
    "cm= confusion_matrix(y_true, y_pred, normalize='pred').round(2) * 100\n",
    "df_cm = pd.DataFrame(cm, index = [i for i in ARTEMIS_EMOTIONS],\n",
    "                     columns = [i for i in ARTEMIS_EMOTIONS])\n",
    "fig = plt.figure(figsize=(16,13))\n",
    "sns.set(font_scale=1)\n",
    "sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 28}, fmt='.0f')\n",
    "plt.xticks(fontsize=36, rotation=90)\n",
    "plt.yticks(fontsize=36, rotation=0)\n",
    "plt.show()\n",
    "fig.savefig(f'{l1}_{l2}.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177a05ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the art genre\n",
    "genres = pd.read_csv('dataset/wiki_art_genre_class.csv')\n",
    "# adding art genre to the dataframe\n",
    "df = pd.merge(lang_df, genres, on=['art_style', 'painting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79eae03",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_genre_counts = df['genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9724965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "emo1 = 'amusement'\n",
    "emo2 = 'disgust'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8ec2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttdf = df[(df[f'{l1}_emo']==EMOTION_ID[emo1])\n",
    "                           &(df[f'{l2}_emo']==EMOTION_ID[emo2])][['utterance', 'image_file', 'genre',\n",
    "                                                                 'en_emo', 'ar_emo', 'ch_emo']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04987e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttdf = ttdf[ttdf['genre']=='nude_painting']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fbc241",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['genre']=='portrait']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a92904",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['en_emo'] < 4)& (df['ar_emo'] >= 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9103081e",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 44\n",
    "print(df.iloc[idx]['utterance'])\n",
    "print(df.iloc[idx][['en_emo', 'ar_emo', 'ch_emo']])\n",
    "Image.open(df.iloc[idx]['image_file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba4f668",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 34\n",
    "print(df.iloc[idx]['utterance'])\n",
    "print(df.iloc[idx][['en_emo', 'ar_emo', 'ch_emo']])\n",
    "Image.open(df.iloc[idx]['image_file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e588c583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 15\n",
    "print(ttdf.iloc[idx]['utterance'])\n",
    "print(ttdf.iloc[idx][['en_emo', 'ar_emo', 'ch_emo']])\n",
    "Image.open(ttdf.iloc[idx]['image_file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b706c986",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 11\n",
    "print(ttdf.iloc[idx]['utterance'])\n",
    "print(ttdf.iloc[idx][['en_emo', 'ar_emo', 'ch_emo']])\n",
    "Image.open(ttdf.iloc[idx]['image_file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba7cf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 10\n",
    "print(ttdf.iloc[idx]['utterance'])\n",
    "print(ttdf.iloc[idx][['en_emo', 'ar_emo', 'ch_emo']])\n",
    "Image.open(ttdf.iloc[idx]['image_file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c16569",
   "metadata": {},
   "outputs": [],
   "source": [
    "conflict_genre_counts = df[(df['ar_emo']==EMOTION_ID['awe'])\n",
    "                           &(df['ch_emo']==EMOTION_ID['fear'])]['genre'].value_counts()\n",
    "#    &(df['utterance'].str.contains('nud'))]\n",
    "zz = (conflict_genre_counts / all_genre_counts).sort_values(ascending=False)\n",
    "plt.bar([z.replace('_', ' ') for z in zz.index], zz.values / sum(zz))\n",
    "plt.xticks(fontsize=18, rotation=90)\n",
    "plt.yticks(fontsize=18, rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb98cced",
   "metadata": {},
   "outputs": [],
   "source": [
    "conflict_genre_counts = df[(df['ar_emo']==EMOTION_ID['contentment'])\n",
    "                           &(df['ch_emo']==EMOTION_ID['sadness'])]['genre'].value_counts()\n",
    "#    &(df['utterance'].str.contains('nud'))]\n",
    "zz = (conflict_genre_counts / all_genre_counts).sort_values(ascending=False)\n",
    "plt.bar(list(zz.index), zz.values)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5f3146",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_report(all_df, 'en', 'ar')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('vad_bert')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4d85a04265eabdb4818588eb8176f04cc8800e0221914484e3dd3bf29608e438"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
